{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='notebook_contents'></a>\n",
    "**Instructions**\n",
    "\n",
    "The [**Required**](#cell_required) \"code\" cell must be run first before running any experiments.  It only needs to be run once.  You should update the apikey **BEFORE** running the cell.  The apikey variable can be found at the beginning of the cell.  Simply update it with the apikey you were given.\n",
    "\n",
    "Go [**here**](https://github.com/IBM/whcs-sample-opendata-notebooks/blob/master/iml-covid-19/README.md) for instructions on obtaining an apikey.\n",
    "\n",
    "_Notebook Contents:_\n",
    "* [Required](#cell_required)\n",
    "* [Experiment 001: Retrieve corpora information](#cell_exp_001)\n",
    "* [Experiment 002: Discover preferred name for a term in specified corpus](#cell_exp_002)\n",
    "* [Experiment 003: Retrieve metadata for a CUI or preferred name](#cell_exp_003)\n",
    "* [Experiment 004: Discover available semantic types in specified corpus](#cell_exp_004)\n",
    "* [Experiment 005: Discover available attributes in specified corpus](#cell_exp_005)\n",
    "* [Experiment 006: Discover concepts by attribute in specified corpus](#cell_exp_006)\n",
    "* [Experiment 007: Discover co-occurring concepts in specified corpus](#cell_exp_007)\n",
    "* [Experiment 008: Discover documents of interest in specified corpus (by terms)](#cell_exp_008)\n",
    "* [Experiment 009: Discover documents of interest in specified corpus (by attributes)](#cell_exp_009)\n",
    "* [Experiment 010: Retrieve metadata for document in specified corpus.](#cell_exp_010)\n",
    "* [Experiment 011: Retrieve content for document in specified corpus.](#cell_exp_011)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cell_exp_001'></a>\n",
    "<hr style=\"height:2px\">\n",
    "\n",
    "[Back to Notebook Contents](#notebook_contents)\n",
    "\n",
    "**Experiment 001:** Retrieve corpora information.\n",
    "\n",
    "Returns:\n",
    "* ok: True|False (when true, returned dataframe data is valid)\n",
    "* df: populated dataframe\n",
    "\n",
    "Note: When ok is False, the dataframe will be populated with a formatted error message that can still be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ok, df = get_corpus_names()\n",
    "\n",
    "# display results\n",
    "display_df(format_df(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cell_exp_002'></a>\n",
    "<hr style=\"height:2px\">\n",
    "\n",
    "[Back to Notebook Contents](#notebook_contents)\n",
    "\n",
    "**Experiment 002:** Discover preferred name for a term in specified corpus.\n",
    "\n",
    "Returns:\n",
    "* ok: True|False (when True, returned dataframe data is valid)\n",
    "* df: populated dataframe\n",
    "\n",
    "Note: When ok is False, the dataframe will be populated with a formatted error message that can still be displayed.\n",
    "\n",
    "Count Explanation:\n",
    "* _results_count_ is the number of times the concept is mentioned in the query results (based on specified term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corpus = \"covid19\"\n",
    "max_names = 5\n",
    "\n",
    "term = input (\"Enter a term: \")\n",
    "ok, df = get_preferred_name(corpus, term, max_names)\n",
    "\n",
    "# display results\n",
    "display_df(format_df(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cell_exp_003'></a>\n",
    "<hr style=\"height:2px\">\n",
    "\n",
    "[Back to Notebook Contents](#notebook_contents)\n",
    "\n",
    "**Experiment 003:** Retrieve metadata for a cui or preferred name in specified corpus.  \n",
    "\n",
    "Returns:\n",
    "* ok: True|False (when True, returned dataframe data is valid)\n",
    "* df: populated dataframe\n",
    "\n",
    "Note: When ok is False, the dataframe will be populated with a formatted error message that can still be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corpus = \"covid19\"\n",
    "\n",
    "concept = input (\"Enter the preferred name or cui for a concept: \")\n",
    "ok, df = get_concept_meta(corpus, concept)\n",
    "\n",
    "# display results\n",
    "display_df(format_df(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cell_exp_004'></a>\n",
    "<hr style=\"height:2px\">\n",
    "\n",
    "[Back to Notebook Contents](#notebook_contents)\n",
    "\n",
    "**Experiment 004:** Discover available semantic types in specified corpus.\n",
    "\n",
    "Returns:\n",
    "* ok: True|False (when True, returned dataframe data is valid)\n",
    "* df: populated dataframe\n",
    "\n",
    "Note: When ok is False, the dataframe will be populated with a formatted error message that can still be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus = \"covid19\"\n",
    "\n",
    "ok, df = get_semantic_types(corpus)\n",
    "\n",
    "# display results\n",
    "display_df(format_df(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cell_exp_005'></a>\n",
    "<hr style=\"height:2px\">\n",
    "\n",
    "[Back to Notebook Contents](#notebook_contents)\n",
    "\n",
    "**Experiment 005:** Discover available attributes in specified corpus.\n",
    "\n",
    "Returns:\n",
    "* ok: True|False (when True, returned dataframe data is valid)\n",
    "* df: populated dataframe\n",
    "\n",
    "Note: When ok is False, the dataframe will be populated with a formatted error message that can still be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus = \"covid19\"\n",
    "\n",
    "ok, df = get_attributes(corpus)\n",
    "\n",
    "# display results\n",
    "display_df(format_df(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cell_exp_006'></a>\n",
    "<hr style=\"height:2px\">\n",
    "\n",
    "[Back to Notebook Contents](#notebook_contents)\n",
    "\n",
    "**Experiment 006:** Discover concepts by attribute in specified corpus.\n",
    "\n",
    "Returns:\n",
    "* ok: True|False (when True, returned dataframe data is valid)\n",
    "* df: populated dataframe\n",
    "\n",
    "Note: When ok is False, the dataframe will be populated with a formatted error message that can still be displayed.\n",
    "\n",
    "Count Explanation:\n",
    "* _corpus_count_ is the number of times the concept is mentioned in the corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corpus = \"covid19\"\n",
    "attrib_id = \"covid-19\"\n",
    "max_concepts = 20\n",
    "ok, df = get_concepts_by_attribute(corpus, attrib_id, max_concepts)\n",
    "\n",
    "if ok:\n",
    "    # wordcloud\n",
    "    freq = dict()\n",
    "    for ind in df.index:\n",
    "        key = str(df['preferred_name'][ind])\n",
    "        value = int(df['corpus_count'][ind])\n",
    "        freq[key] = value\n",
    "    display_wc_freq(freq)\n",
    "\n",
    "# display results\n",
    "display_df(format_df(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cell_exp_007'></a>\n",
    "<hr style=\"height:2px\">\n",
    "\n",
    "[Back to Notebook Contents](#notebook_contents)\n",
    "\n",
    "**Experiment 007:** Discover co-occurring disorders, drugs or genes for concept in specified corpus.\n",
    "\n",
    "This experiment calls two methods.  One call to retrieve concept metadata for a term.  Subsequent call, uses that metadata to retrieve co-occurring concepts (for the specified category).  Both of the methods have the same return signature.\n",
    "\n",
    "Returns:\n",
    "* ok: True|False (when True, returned dataframe data is valid)\n",
    "* df: populated dataframe\n",
    "\n",
    "Note: When ok is False, the dataframe will be populated with a formatted error message that can still be displayed.\n",
    "\n",
    "Count Explanation:\n",
    "* _results_count_ is the number of times the concept is mentioned in the query results (based on specified term)\n",
    "* _corpus_count_ is the number of times the concept is mentioned in the corpus\n",
    "\n",
    "The _corpus_count_ will always be less than or equal to the _results_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corpus = \"covid19\"\n",
    "term = \"human coronavirus\"\n",
    "cotype = \"drugs\" # possible values: \"disorders\", \"drugs\" or \"genes\".\n",
    "\n",
    "# retrieve concept metadata for term\n",
    "ok, df = get_preferred_name(corpus, term, 1)\n",
    "if ok:\n",
    "    concept = dict()\n",
    "    concept[\"cui\"] = df.iloc[0]['cui']\n",
    "    concept[\"preferred_name\"] = df.iloc[0]['preferred_name']\n",
    "    concept[\"semantic_type\"] = df.iloc[0]['semantic_type']\n",
    "\n",
    "# display results\n",
    "display_df(format_df(df))\n",
    "\n",
    "if ok: # can only continue if we previously retrieved a valid concept\n",
    "\n",
    "    # get co-occurring concepts\n",
    "    ok, df = get_co_occurring_concepts(concept, cotype)\n",
    "\n",
    "    if ok:\n",
    "        # wordcloud\n",
    "        freq = dict()\n",
    "        for ind in df.index:\n",
    "            key = str(df['preferred_name'][ind])\n",
    "            value = int(df['corpus_count'][ind])\n",
    "            freq[key] = value\n",
    "        display_wc_freq(freq)\n",
    "\n",
    "    # display results\n",
    "    display_df(format_df(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cell_exp_008'></a>\n",
    "<hr style=\"height:2px\">\n",
    "\n",
    "[Back to Notebook Contents](#notebook_contents)\n",
    "\n",
    "**Experiment 008:** Discover documents of interest in specified corpus (by terms).\n",
    "\n",
    "Returns:\n",
    "* ok: True|False (when True, returned document count and dataframe data are valid)\n",
    "* df: populated dataframe\n",
    "\n",
    "Note: When ok is False, the dataframe will be populated with a formatted error message that can still be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"covid19\"\n",
    "bool_expr = \"AND\" # \"AND\" or \"OR\"\n",
    "terms = [\n",
    "    \"virus\",\n",
    "    \"lung\"\n",
    "]\n",
    "max_docs = 10\n",
    "\n",
    "ok, doc_count, df = get_documents_by_terms(corpus, bool_expr, terms, max_docs)\n",
    "\n",
    "# display results\n",
    "if ok:\n",
    "    print(\"doc_count:\", doc_count)\n",
    "display_df(format_df(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cell_exp_009'></a>\n",
    "<hr style=\"height:2px\">\n",
    "\n",
    "[Back to Notebook Contents](#notebook_contents)\n",
    "\n",
    "**Experiment 009:** Discover documents of interest in specified corpus (by attributes).\n",
    "\n",
    "Returns:\n",
    "* ok: True|False (when True, returned document count and dataframe data are valid)\n",
    "* df: populated dataframe\n",
    "\n",
    "Note: When ok is False, the dataframe will be populated with a formatted error message that can still be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"covid19\"\n",
    "bool_expr = \"AND\" # \"AND\" or \"OR\"\n",
    "attribs = [\n",
    "    \"human_coronavirus\"\n",
    "]\n",
    "max_docs = 10\n",
    "\n",
    "ok, doc_count, df = get_documents_by_attributes(corpus, bool_expr, attribs, max_docs)\n",
    "\n",
    "# display results\n",
    "if ok:\n",
    "    print(\"doc_count:\", doc_count)\n",
    "display_df(format_df(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cell_exp_010'></a>\n",
    "<hr style=\"height:2px\">\n",
    "\n",
    "[Back to Notebook Contents](#notebook_contents)\n",
    "\n",
    "**Experiment 010:** Retrieve metadata for document in specified corpus.\n",
    "\n",
    "Returns:\n",
    "* ok: True|False (when True, returned document count and dataframe data are valid)\n",
    "* df: populated dataframe\n",
    "\n",
    "Note: When ok is False, the dataframe will be populated with a formatted error message that can still be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corpus = \"covid19\"\n",
    "docid = \"7086750\"\n",
    "\n",
    "ok, df = get_document_meta(corpus, docid)\n",
    "\n",
    "# display results\n",
    "display_df(format_df(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cell_exp_011'></a>\n",
    "<hr style=\"height:2px\">\n",
    "\n",
    "[Back to Notebook Contents](#notebook_contents)\n",
    "\n",
    "**Experiment 011:** Retrieve content for document in specified corpus.\n",
    "\n",
    "Returns:\n",
    "* ok: True|False (when True, returned document count and dataframe data are valid)\n",
    "* df: populated dataframe\n",
    "\n",
    "Note: When ok is False, the dataframe will be populated with a formatted error message that can still be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"covid19\"\n",
    "docid = \"7086750\"\n",
    "\n",
    "ok, df = get_document(corpus, docid)\n",
    "\n",
    "if ok:\n",
    "    # wordcloud\n",
    "    title = df.iloc[0]['value'] \n",
    "    display_wc_text(title)\n",
    "\n",
    "# display results\n",
    "display_df(format_df(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cell_required'></a>\n",
    "<hr style=\"height:2px\">\n",
    "\n",
    "[Back to Notebook Contents](#notebook_contents)\n",
    "\n",
    "**Required:** Run the following cell to load IML functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# substitute APIKEY with the apikey you were given\n",
    "apikey = \"APIKEY\"\n",
    "\n",
    "# uncomment the following line to pip install wordcloud (if you do not already have it installed in your environment)\n",
    "# !pip install wordcloud\n",
    "\n",
    "# Copyright 2020 IBM All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#   \n",
    "# http://www.apache.org/licenses/LICENSE-2.0   \n",
    "#   \n",
    "# Unless required by applicable law or agreed to in writing, software   \n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,   \n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.   \n",
    "# See the License for the specific language governing permissions and   \n",
    "# limitations under the License.\n",
    "\n",
    "# endpoint config\n",
    "endpoint = \"https://us-south.wh-iml.cloud.ibm.com/wh-iml/api/v1\"\n",
    "\n",
    "# needed imports\n",
    "import json\n",
    "import requests\n",
    "import base64\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud # https://anaconda.org/conda-forge/wordcloud\n",
    "\n",
    "# prepare auth header\n",
    "apikey_enc = base64.b64encode((\"apikey:\"+apikey).encode()).decode()\n",
    "headers = {\"Authorization\":\"Basic %s\" % apikey_enc}    \n",
    "\n",
    "\n",
    "def format_error(level, message, description):\n",
    "    out = []\n",
    "    item = dict()\n",
    "    item[\"key\"] = \"level\"\n",
    "    item[\"value\"] = level\n",
    "    out.append(item)\n",
    "    item = dict()\n",
    "    item[\"key\"] = \"message\"\n",
    "    item[\"value\"] = message\n",
    "    out.append(item)\n",
    "    item = dict()\n",
    "    item[\"key\"] = \"description\"\n",
    "    item[\"value\"] = description\n",
    "    out.append(item)\n",
    "    return out\n",
    "\n",
    "\n",
    "def format_rest_error(resp):\n",
    "    if (str(resp)).startswith(\"<Response\"):\n",
    "        print(resp)\n",
    "        out = []\n",
    "    else:        \n",
    "        resp_data = json.loads(resp.content)\n",
    "        out = []\n",
    "        item = dict()\n",
    "        item[\"key\"] = \"code\"\n",
    "        item[\"value\"] = resp_data['code']\n",
    "        out.append(item)\n",
    "        item = dict()\n",
    "        item[\"key\"] = \"message\"\n",
    "        item[\"value\"] = resp_data['message']\n",
    "        out.append(item)\n",
    "        item = dict()\n",
    "        item[\"key\"] = \"level\"\n",
    "        item[\"value\"] = resp_data['level']\n",
    "        out.append(item)\n",
    "        item = dict()\n",
    "        item[\"key\"] = \"description\"\n",
    "        item[\"value\"] = resp_data['description']\n",
    "        out.append(item)\n",
    "        item = dict()\n",
    "        item[\"key\"] = \"correlationId\"\n",
    "        item[\"value\"] = resp_data['correlationId']\n",
    "        out.append(item)\n",
    "    return out\n",
    "\n",
    "\n",
    "def on_clear_button_clicked(b):\n",
    "    clear_output(wait=False)\n",
    "\n",
    "    \n",
    "def clear_btn():\n",
    "    clear_button = widgets.Button(description=\"Clear\")\n",
    "    display(clear_button)\n",
    "    clear_button.on_click(on_clear_button_clicked)\n",
    "    return\n",
    "\n",
    "\n",
    "def display_df(df):\n",
    "    display(df)\n",
    "    clear_btn()\n",
    "    return\n",
    "\n",
    "\n",
    "def format_df(df, max_rows=None):\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    styles = [\n",
    "        dict(selector=\"th\", props=[(\"text-align\", \"left\")]),\n",
    "        dict(selector=\"td\", props=[(\"text-align\", \"left\")])\n",
    "    ]\n",
    "    if max_rows is not None:\n",
    "        return df.head(max_rows).style.set_table_styles(styles)\n",
    "    else:\n",
    "        return df.style.set_table_styles(styles)\n",
    "\n",
    "\n",
    "def display_wc_text(text):\n",
    "    wordcloud = WordCloud(width=800, height=400, max_font_size=40).generate(text)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    clear_btn()\n",
    "    return\n",
    "\n",
    "\n",
    "def display_wc_freq(freq):\n",
    "    wordcloud = WordCloud(width=800, height=400, max_font_size=40).generate_from_frequencies(freq)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    clear_btn()\n",
    "    return\n",
    "\n",
    "\n",
    "def get_corpus_names():\n",
    "    ok = False\n",
    "    url_parms_template = \"/corpora?version=<version>&verbose=false\"\n",
    "    url_parms = url_parms_template.replace(\"<version>\", datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "    \n",
    "    # make rest call and process response\n",
    "    resp = requests.get(endpoint + url_parms, headers=headers)\n",
    "    \n",
    "    if resp.ok:\n",
    "        resp_data = json.loads(resp.content)\n",
    "        out = []\n",
    "        for corpus in resp_data[\"corpora\"]:\n",
    "            item = dict()\n",
    "            item[\"corpus_name\"] = corpus[\"corpusName\"]\n",
    "            item[\"ontologies\"] = corpus[\"ontologies\"]\n",
    "            item[\"descriptive_name\"] = corpus[\"descriptiveName\"]\n",
    "            out.append(item)\n",
    "        df = pd.DataFrame(out)\n",
    "        df = df.sort_values(\"corpus_name\", ascending=True)\n",
    "        ok = True\n",
    "    else:\n",
    "        df = pd.DataFrame(format_rest_error(resp))\n",
    "    return ok, df\n",
    "\n",
    "\n",
    "def get_preferred_name(corpus, term, limit):\n",
    "    ok = False\n",
    "    ontology = \"umls\"\n",
    "    url_parms_template = \"/corpora/<corpus>/search/typeahead?version=<version>&query=<term>&ontologies=<ontology>&verbose=false&_limit=<limit>&max_hit_count=5000000&no_duplicates=true\"\n",
    "    url_parms = url_parms_template.replace(\"<corpus>\", corpus).replace(\"<term>\", term).replace(\"<ontology>\", ontology).replace(\"<limit>\", str(limit)).replace(\"<version>\", datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    # make rest call and process response\n",
    "    resp = requests.get(endpoint + url_parms, headers=headers)\n",
    "    if resp.ok:\n",
    "        resp_data = json.loads(resp.content)\n",
    "        concepts = resp_data[\"concepts\"]\n",
    "        if len(concepts) > 0:\n",
    "            out = []\n",
    "            for concept in concepts:\n",
    "                item = dict()\n",
    "                item[\"cui\"] = concept[\"cui\"]\n",
    "                if \"preferredName\" in concept.keys():\n",
    "                    item[\"preferred_name\"] = concept[\"preferredName\"]\n",
    "                else:\n",
    "                    item[\"preferred_name\"] = concept[\"cui\"]\n",
    "                item[\"semantic_type\"] = concept[\"semanticType\"]\n",
    "                item[\"results_count\"] = concept[\"hitCount\"]\n",
    "                out.append(item)\n",
    "            df = pd.DataFrame(out)\n",
    "            df = df.sort_values(\"results_count\", ascending=False)\n",
    "            ok = True\n",
    "        else:\n",
    "            out = format_error(\"ERROR\", \"No concepts found for: \" + term, \"Re-run with an alternate term.\")\n",
    "            df = pd.DataFrame(out)\n",
    "    else:\n",
    "        df = pd.DataFrame(format_rest_error(resp))\n",
    "    return ok, df\n",
    "\n",
    "\n",
    "def get_concept_meta(corpus, concept):\n",
    "    ok = False\n",
    "    url_parms_template = \"/corpora/<corpus>/concepts/<concept>?version=<version>&ontology=concepts&tree_layout=false\"\n",
    "    url_parms = url_parms_template.replace(\"<corpus>\", corpus).replace(\"<concept>\", concept).replace(\"<version>\", datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    # make rest call and process response\n",
    "    resp = requests.get(endpoint + url_parms, headers=headers)\n",
    "    if resp.ok:\n",
    "        concept = json.loads(resp.content)\n",
    "        out = []\n",
    "        if \"cui\" in concept.keys():\n",
    "            item = dict()\n",
    "            item[\"key\"] = \"cui\"\n",
    "            item[\"value\"] = concept[\"cui\"]\n",
    "            out.append(item)\n",
    "        if \"ontology\" in concept.keys():\n",
    "            item = dict()\n",
    "            item[\"key\"] = \"ontology\"\n",
    "            item[\"value\"] = concept[\"ontology\"]\n",
    "            out.append(item)\n",
    "        if \"preferredName\" in concept.keys():\n",
    "            item = dict()\n",
    "            item[\"key\"] = \"preferred_name\"\n",
    "            item[\"value\"] = concept[\"preferredName\"]\n",
    "            out.append(item)\n",
    "        if \"semanticTypes\" in concept.keys():\n",
    "            item = dict()\n",
    "            item[\"key\"] = \"semantic_types\"\n",
    "            item[\"value\"] = concept[\"semanticTypes\"]\n",
    "            out.append(item)\n",
    "        if \"surfaceForms\" in concept.keys():\n",
    "            item = dict()\n",
    "            item[\"key\"] = \"surface_forms\"\n",
    "            item[\"value\"] = concept[\"surfaceForms\"]\n",
    "            out.append(item)\n",
    "        if \"definition\" in concept.keys():\n",
    "            item = dict()\n",
    "            item[\"key\"] = \"definition\"\n",
    "            item[\"value\"] = concept[\"definition\"]\n",
    "            out.append(item)\n",
    "        if \"hasParents\" in concept.keys():\n",
    "            item = dict()\n",
    "            item[\"key\"] = \"has_parents\"\n",
    "            item[\"value\"] = concept[\"hasParents\"]\n",
    "            out.append(item)\n",
    "        if \"hasChildren\" in concept.keys():\n",
    "            item = dict()\n",
    "            item[\"key\"] = \"has_children\"\n",
    "            item[\"value\"] = concept[\"hasChildren\"]\n",
    "            out.append(item)\n",
    "        if \"hasSiblings\" in concept.keys():\n",
    "            item = dict()\n",
    "            item[\"key\"] = \"has_siblings\"\n",
    "            item[\"value\"] = concept[\"hasSiblings\"]\n",
    "            out.append(item)\n",
    "        df = pd.DataFrame(out)\n",
    "        ok = True\n",
    "    else:\n",
    "        df = pd.DataFrame(format_rest_error(resp))\n",
    "    return ok, df\n",
    "\n",
    "\n",
    "def get_semantic_types(corpus):\n",
    "    ok = False\n",
    "    search = {\n",
    "        \"returns\": {\n",
    "            \"types\": {\n",
    "                \"ontology\": \"concepts\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    url_parms_template = \"/corpora/<corpus>/search?version=<version>&verbose=false\"\n",
    "    url_parms = url_parms_template.replace(\"<corpus>\", corpus).replace(\"<version>\", datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    # make rest call and process response\n",
    "    resp = requests.post(endpoint + url_parms, json=search, headers=headers)\n",
    "    if resp.ok:\n",
    "        resp_data = json.loads(resp.content)\n",
    "        sorted_list = sorted(resp_data[\"types\"])    \n",
    "        out = []\n",
    "        for semantic_type in sorted_list:\n",
    "            item = dict()\n",
    "            item[\"name\"] = semantic_type\n",
    "            out.append(item)\n",
    "        df = pd.DataFrame(out)\n",
    "        df = df.sort_values(\"name\", ascending=True)\n",
    "        ok = True\n",
    "    else:\n",
    "        df = pd.DataFrame(format_rest_error(resp))\n",
    "    return ok, df\n",
    "\n",
    "\n",
    "def get_attributes(corpus):\n",
    "    ok = False\n",
    "    search = {\n",
    "        \"query\": {},\n",
    "        \"returns\": {\n",
    "            \"attributes\": {}\n",
    "        }\n",
    "    }    \n",
    "    url_parms_template = \"/corpora/<corpus>/search?version=<version>&verbose=false\"\n",
    "    url_parms = url_parms_template.replace(\"<corpus>\", corpus).replace(\"<version>\", datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    # make rest call and process response\n",
    "    resp = requests.post(endpoint + url_parms, json=search, headers=headers)\n",
    "    if resp.ok:\n",
    "        resp_data = json.loads(resp.content)\n",
    "        out = []\n",
    "        for doc in resp_data[\"attributes\"]:\n",
    "            item = dict()\n",
    "            item[\"attrib_id\"] = doc[\"attributeId\"]\n",
    "            item[\"display_name\"] = doc[\"displayName\"]\n",
    "            out.append(item)\n",
    "        df = pd.DataFrame(out)\n",
    "        df = df.sort_values(\"attrib_id\", ascending=True)\n",
    "        ok = True\n",
    "    else:\n",
    "        df = pd.DataFrame(format_rest_error(resp))\n",
    "    return ok, df\n",
    "\n",
    "\n",
    "def get_concepts_by_attribute(corpus, attrib_id, max_concepts=20):\n",
    "    ok = False\n",
    "    search = {\n",
    "      \"query\": {\n",
    "        \"title\": {\n",
    "          \"boost\": \"1\"\n",
    "        }\n",
    "      },\n",
    "      \"returns\": {\n",
    "        \"typeahead\": {\n",
    "          \"ontology\": \"concepts\",\n",
    "          \"query\": \"\",\n",
    "          \"noDuplicates\": True,\n",
    "          \"limit\": 20,\n",
    "          \"scope\": \"query\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    search['returns']['typeahead']['query'] = attrib_id\n",
    "    search['returns']['typeahead']['limit'] = max_concepts\n",
    "    url_parms_template = \"/corpora/<corpus>/search?version=<version>&verbose=false\"\n",
    "    url_parms = url_parms_template.replace(\"<corpus>\", corpus).replace(\"<version>\", datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    # make rest call and process response\n",
    "    resp = requests.post(endpoint + url_parms, json=search, headers=headers)\n",
    "    if resp.ok:\n",
    "        resp_data = json.loads(resp.content)\n",
    "        concepts = resp_data[\"typeahead\"]\n",
    "        if len(concepts) > 0:\n",
    "            out = []\n",
    "            for concept in concepts:\n",
    "                item = dict()\n",
    "                item[\"cui\"] = concept[\"cui\"]\n",
    "                item[\"preferred_name\"] = concept[\"preferredName\"]\n",
    "                item[\"semantic_type\"] = concept[\"semanticType\"]\n",
    "                item[\"corpus_count\"] = concept[\"hitCount\"]\n",
    "                out.append(item)\n",
    "            df = pd.DataFrame(out)\n",
    "            df = df.sort_values(\"corpus_count\", ascending=False)\n",
    "            ok = True\n",
    "        else:\n",
    "            out = format_error(\"ERROR\", \"No concepts found for: \" + attrib_id, \"Re-run with an alternate attribute.\")\n",
    "            df = pd.DataFrame(out)\n",
    "    else:\n",
    "        df = pd.DataFrame(format_rest_error(resp))\n",
    "    return ok, df\n",
    "\n",
    "\n",
    "def get_co_occurring_concepts(concept, cotype, limit=100):\n",
    "    ok = False\n",
    "    search = {\n",
    "      \"query\": {\n",
    "        \"boolExpression\": \"\",\n",
    "        \"concepts\": [\n",
    "          {\n",
    "            \"boolOperand\": \"\",\n",
    "            \"ontology\": \"concepts\",\n",
    "            \"cui\": \"\",\n",
    "            \"rank\": 10,\n",
    "            \"semanticType\": \"\"\n",
    "          }\n",
    "        ],\n",
    "        \"title\": {\n",
    "          \"boost\": \"1\"\n",
    "        }\n",
    "      },\n",
    "      \"returns\": {\n",
    "        \"concepts\": {\n",
    "          \"ontology\": \"concepts\",\n",
    "          \"limit\": 100,\n",
    "          \"types\": [],\n",
    "          \"section\": \"*\",\n",
    "          \"mode\": \"popular\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    disorder_types = [\n",
    "        \"AcquiredAbnormality\",\n",
    "        \"AnatomicalAbnormality\",\n",
    "        \"CellOrMolecularDysfunction\",\n",
    "        \"CongenitalAbnormality\",\n",
    "        \"DiseaseOrSyndrome\",\n",
    "        \"ExperimentalModelofDisease\",\n",
    "        \"InjuryOrPoisoning\",\n",
    "        \"MentalOrBehavioralDysfunction\",\n",
    "        \"NeoplasticProcess\",\n",
    "        \"PathologicFunction\"\n",
    "    ]\n",
    "    \n",
    "    drug_types = [\n",
    "        \"Antibiotic\",\n",
    "        \"ClinicalDrug\",\n",
    "        \"Hormone\",\n",
    "        \"PharmacologicSubstance\"\n",
    "    ]\n",
    "    \n",
    "    gene_types = [\n",
    "        \"AminoAcidSequence\",\n",
    "        \"CarbohydrateSequence\",\n",
    "        \"GeneOrGenome\",\n",
    "        \"MolecularSequence\",\n",
    "        \"NucleotideSequence\"\n",
    "    ]\n",
    "\n",
    "    url_parms_template = \"/corpora/<corpus>/search?version=<version>&verbose=false\"\n",
    "    url_parms = url_parms_template.replace(\"<corpus>\", corpus).replace(\"<version>\", datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "    \n",
    "    # prepare search\n",
    "    search['query']['boolExpression'] = concept['preferred_name']\n",
    "    search['query']['concepts'][0]['boolOperand'] = concept['preferred_name']\n",
    "    search['query']['concepts'][0]['cui'] = concept['cui']\n",
    "    search['query']['concepts'][0]['semanticType'] = concept['semantic_type']\n",
    "    search['returns']['concepts']['limit'] = limit\n",
    "    if cotype == \"disorders\":\n",
    "        search['returns']['concepts']['types'] = disorder_types\n",
    "    elif cotype == \"drugs\":\n",
    "        search['returns']['concepts']['types'] = drug_types\n",
    "    elif cotype == \"genes\":\n",
    "        search['returns']['concepts']['types'] = gene_types\n",
    "    else:\n",
    "        out = format_error(\"ERROR\", \"Unsupported co-occurring concept type specified\", \"Re-run with a valid co-occurring concept type (disorders, drugs, genes).\")\n",
    "        df = pd.DataFrame(out)\n",
    "        return ok, df # can't continue, so return\n",
    "        \n",
    "    # make rest call and process response\n",
    "    resp = requests.post(endpoint + url_parms, json=search, headers=headers)\n",
    "    if resp.ok:\n",
    "        resp_data = json.loads(resp.content)\n",
    "        concepts = resp_data[\"concepts\"]\n",
    "        out = []\n",
    "        for concept in concepts:\n",
    "            item = dict()\n",
    "            item[\"cui\"] = concept[\"cui\"]\n",
    "            item[\"preferred_name\"] = concept[\"preferredName\"]\n",
    "            item[\"semantic_type\"] = concept[\"semanticType\"]\n",
    "            item[\"results_count\"] = concept[\"hitCount\"]\n",
    "            item[\"corpus_count\"] = concept[\"count\"]\n",
    "            out.append(item)\n",
    "        df = pd.DataFrame(out)\n",
    "        df = df.sort_values(\"results_count\", ascending=False)\n",
    "        ok = True\n",
    "    else:\n",
    "        df = pd.DataFrame(format_rest_error(resp))     \n",
    "    return ok, df\n",
    "\n",
    "\n",
    "def get_documents_by_terms(corpus, bool_expr, terms, limit=10):\n",
    "    ok = False\n",
    "    search = {\n",
    "        \"query\": {\n",
    "            \"boolExpression\": \"\",\n",
    "            \"concepts\" : [],\n",
    "            \"title\": {\n",
    "              \"boost\": \"1\"\n",
    "            }\n",
    "        },\n",
    "        \"returns\": {\n",
    "            \"documents\": {\n",
    "              \"limit\": \"10\",\n",
    "              \"offset\": \"0\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    url_parms_template = \"/corpora/<corpus>/search?version=<version>&verbose=false\"\n",
    "    url_parms = url_parms_template.replace(\"<corpus>\", corpus).replace(\"<version>\", datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "    \n",
    "    # prepare boolean expression\n",
    "    terms_formatted = []\n",
    "    for term in terms:\n",
    "        terms_formatted.append('(' + term + ')')\n",
    "    search['query']['boolExpression'] = (' ' + bool_expr + ' ').join(terms_formatted)\n",
    "                               \n",
    "    # prepare concepts\n",
    "    concepts = []\n",
    "    for term in terms:\n",
    "        concept = dict()\n",
    "        concept.update({\"ontology\":\"text\"})\n",
    "        concept.update({\"rank\":10})\n",
    "        concept.update({\"boolOperand\":term})\n",
    "        concept.update({\"text\":term})\n",
    "        concept.update({\"proximity\":0})\n",
    "        concepts.append(concept)\n",
    "    search['query']['concepts'] = concepts\n",
    "                               \n",
    "    search['returns']['documents']['limit'] = limit\n",
    "\n",
    "    # make rest call and process response\n",
    "    resp = requests.post(endpoint + url_parms, json=search, headers=headers)\n",
    "    if resp.ok:\n",
    "        resp_data = json.loads(resp.content)\n",
    "        doc_count = resp_data[\"totalDocumentCount\"]\n",
    "        out = []\n",
    "        for doc in resp_data[\"documents\"]:\n",
    "            item = dict()\n",
    "            item[\"doc_id\"] = doc[\"documentId\"]\n",
    "            item[\"title\"] = doc[\"title\"]\n",
    "            out.append(item)\n",
    "        df = pd.DataFrame(out)\n",
    "        ok = True\n",
    "    else:\n",
    "        doc_count = 0\n",
    "        df = pd.DataFrame(format_rest_error(resp))        \n",
    "    return ok, doc_count, df\n",
    "\n",
    "\n",
    "def get_documents_by_attributes(corpus, bool_expr, attribs, limit=10):\n",
    "    ok = False\n",
    "    search = {\n",
    "        \"query\": {\n",
    "            \"boolExpression\": \"\",\n",
    "            \"rankedSearch\": True,\n",
    "            \"concepts\": [\n",
    "            ]\n",
    "        },\n",
    "        \"returns\": {\n",
    "            \"documents\": {\n",
    "              \"limit\": \"10\",\n",
    "              \"offset\": \"0\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    concepts = []\n",
    "    for attrib in attribs:\n",
    "        item = dict()\n",
    "        item[\"boolOperand\"] = attrib\n",
    "        item[\"ontology\"] = \"attributes\"\n",
    "        item[\"cui\"] = \"*\"\n",
    "        item[\"rank\"] = 10\n",
    "        item[\"semanticType\"] = attrib\n",
    "        concepts.append(item)\n",
    "    \n",
    "    url_parms_template = \"/corpora/<corpus>/search?version=<version>&verbose=false\"\n",
    "    url_parms = url_parms_template.replace(\"<corpus>\", corpus).replace(\"<version>\", datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "    search['query']['boolExpression'] = (' ' + bool_expr + ' ').join(attribs)\n",
    "    search['query']['concepts'] = concepts\n",
    "    search['returns']['documents']['limit'] = limit\n",
    "\n",
    "    # make rest call and process response\n",
    "    resp = requests.post(endpoint + url_parms, json=search, headers=headers)\n",
    "    if resp.ok:\n",
    "        resp_data = json.loads(resp.content)\n",
    "        doc_count = resp_data[\"totalDocumentCount\"]\n",
    "        out = []\n",
    "        for doc in resp_data[\"documents\"]:\n",
    "            item = dict()\n",
    "            item[\"doc_id\"] = doc[\"documentId\"]\n",
    "            item[\"title\"] = doc[\"title\"]\n",
    "            out.append(item)\n",
    "        df = pd.DataFrame(out)\n",
    "        ok = True\n",
    "    else:\n",
    "        doc_count = 0\n",
    "        df = pd.DataFrame(format_rest_error(resp))                \n",
    "    return ok, doc_count, df\n",
    "\n",
    "\n",
    "def get_document_meta(corpus, docid):\n",
    "    ok = False\n",
    "    url_parms_template = \"/corpora/<corpus>/documents/<docid>?version=<version>&verbose=true\"\n",
    "    url_parms = url_parms_template.replace(\"<corpus>\", corpus).replace(\"<docid>\", docid).replace(\"<version>\", datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    # make rest call and process response\n",
    "    resp = requests.get(endpoint + url_parms, headers=headers)\n",
    "    if resp.ok:\n",
    "        resp_data = json.loads(resp.content)\n",
    "        out = []\n",
    "        meta = resp_data[\"metadata\"]\n",
    "        for key in meta.keys():\n",
    "            item = dict()\n",
    "            item[\"key\"] = key\n",
    "            item[\"value\"] = meta[key]\n",
    "            out.append(item)\n",
    "        df = pd.DataFrame(out)\n",
    "        ok = True\n",
    "    else:\n",
    "        df = pd.DataFrame(format_rest_error(resp))                \n",
    "    return ok, df\n",
    "\n",
    "\n",
    "def get_document(corpus, docid):\n",
    "    ok = False\n",
    "    url_parms_template = \"/corpora/<corpus>/documents/<docid>?version=<version>&verbose=true\"\n",
    "    url_parms = url_parms_template.replace(\"<corpus>\", corpus).replace(\"<docid>\", docid).replace(\"<version>\", datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    # make rest call and process response\n",
    "    resp = requests.get(endpoint + url_parms, headers=headers)\n",
    "    if resp.ok:\n",
    "        resp_data = json.loads(resp.content)\n",
    "        out = []\n",
    "        item = dict()\n",
    "        item[\"key\"] = \"title\"\n",
    "        item[\"value\"] = resp_data[\"title\"]\n",
    "        out.append(item)\n",
    "        item = dict()\n",
    "        item[\"key\"] = \"abstract\"\n",
    "        item[\"value\"] = \"\"\n",
    "        if \"abstract\" in resp_data[\"sections\"].keys():\n",
    "            item[\"value\"] = resp_data[\"sections\"][\"abstract\"]\n",
    "        out.append(item)\n",
    "        df = pd.DataFrame(out)\n",
    "        ok = True\n",
    "    else:\n",
    "        df = pd.DataFrame(format_rest_error(resp))                \n",
    "    return ok, df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Notebook Contents](#notebook_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}